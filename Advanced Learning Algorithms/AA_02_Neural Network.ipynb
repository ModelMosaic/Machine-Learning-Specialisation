{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f8f3ed6-5020-44b0-997a-8ca2fcf2e894",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635c92f-451b-4ee7-9c70-d81327eea3e6",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23712fbe-da4a-44d6-923a-2418535a0db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17adbfec-9210-46ce-9e04-883e5c1734af",
   "metadata": {},
   "source": [
    "## 1. Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ca074-afee-4cf0-95e6-85ccac1488e4",
   "metadata": {},
   "source": [
    "We'll use the classic Iris dataset which consists of 3 classes of 50 instances each, where each class refers to a type of iris plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb1c56-b4fa-48bf-86d3-119b5c102686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding of labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67ddf8-f9d9-43d2-a4e0-ce59b88f0047",
   "metadata": {},
   "source": [
    "## 2. Normalising the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68653c9-5b1d-4ca2-9b6f-9d209fac4feb",
   "metadata": {},
   "source": [
    "We'll normalize the input features using StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5a608-9dd7-4984-a84b-423c7d1c0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea4f8a-56df-4fef-80f4-9eec13c8b48e",
   "metadata": {},
   "source": [
    "## 3. Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ceba38-522a-4227-8be9-a2650949e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network model using the Sequential API\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),  # Hidden layer with 10 neurons\n",
    "    tf.keras.layers.Dense(3, activation='softmax')                   # Output layer with 3 neurons (one for each class)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab84df-29ed-4380-9d0d-e5607ab83b88",
   "metadata": {},
   "source": [
    "### 3.1 Epochs and Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc16ef8-8266-4eb9-bd90-75933b03bade",
   "metadata": {},
   "source": [
    "We'll train the model for 50 epochs using a batch size of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd853a-d3a1-40be-bf46-a1c19bea0f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f236b8-e579-49eb-9031-e473592ba10a",
   "metadata": {},
   "source": [
    "### 3.2 Updating Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8b269-58ba-4596-9230-98ff6fb9c551",
   "metadata": {},
   "source": [
    "We define the optimizer (for updating weights), loss, and also metrics we're interested in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91dfcca-19e0-4bd3-b131-a73dfa27ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cebfec-5e5a-4a44-ab96-d8445c8bc744",
   "metadata": {},
   "source": [
    "Now, train the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd55354-a05b-46e7-8f9e-42df58245d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a5756-f113-4c09-8e2b-c64a5fffb219",
   "metadata": {},
   "source": [
    "### 3.3 Prediction\n",
    "\n",
    "Once the model is trained, we can make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89301da8-e388-4234-98dc-37f40350673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predicted_classes = tf.argmax(predictions, axis=1)\n",
    "\n",
    "# If you want to see the predicted classes:\n",
    "print(predicted_classes.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4358097-acf9-4744-927f-c62bb6af3340",
   "metadata": {},
   "source": [
    "## 4. Layer Functions\n",
    "\n",
    "In the model we've constructed, we've used:\n",
    "\n",
    "- `tf.keras.layers.Dense`: Fully connected layer, which connects inputs with every neuron in the layer.\n",
    "\n",
    "#### Activation functions:\n",
    "- `relu`: Rectified Linear Unit. An activation function which is defined as \n",
    "  $$\n",
    "  f(x) = \\max(0, x)\n",
    "  $$\n",
    "  It replaces negative values with zero and passes positive values as they are.\n",
    "\n",
    "- `softmax`: Computes the normalized exponential of every unit in the layer. Useful for multi-class classification, as it provides a distribution of probabilities across the output classes.\n",
    "\n",
    "Make sure to install the necessary packages (`tensorflow` and `sklearn`) if you haven't already.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
