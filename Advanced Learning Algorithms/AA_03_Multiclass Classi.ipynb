{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f4495f-fa11-4f53-80f2-3c25680172cd",
   "metadata": {},
   "source": [
    "# Multi Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90117bbb-b728-4d4b-ba54-cc5ff32a8649",
   "metadata": {},
   "source": [
    "## 1. Theory Introduction to Multiclass Classification\n",
    "\n",
    "Multiclass classification, sometimes called multinomial classification, is the problem of classifying instances into one of three or more classes. While binary classification deals with two classes, multiclass classification deals with three or more.\n",
    "\n",
    "For example, imagine an image recognition system that needs to classify images into categories like \"cat\", \"dog\", \"bird\", etc. This would be a multiclass classification problem.\n",
    "\n",
    "Common strategies to handle multiclass classification problems include:\n",
    "- **One-vs-All (OvA)**: For N classes, N binary classifiers are trained. Each determines whether an instance belongs to its class or not.\n",
    "- **One-vs-One (OvO)**: For N classes, a binary classifier is trained for every pair of classes.\n",
    "- **Softmax Regression or Multinomial Logistic Regression**: When the classes are mutually exclusive.\n",
    "\n",
    "In this example, we'll be using Softmax Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c9caef-1f0e-4dce-8916-2093d9721de8",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68425b-8a5f-4464-a1ac-7bb80fee3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2125764-0b11-4f30-8632-df0e71cc65b8",
   "metadata": {},
   "source": [
    "## 2. Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de2079-b08d-4887-9300-fa8f1e6ceea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with 3 classes\n",
    "X, y = make_blobs(n_samples=1000, centers=3, random_state=42)\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# One-hot encoding the target variable\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8baa44b-d045-484b-9f4e-08f24a64544c",
   "metadata": {},
   "source": [
    "## 3. Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba486540-0d18-4ec0-b71a-0f83345c6787",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_dim=2, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 neurons for 3 classes, with softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, epochs=50, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b989d2f-7c11-4560-84f3-d413e5bbe012",
   "metadata": {},
   "source": [
    "## 4. Explanation\n",
    "\n",
    "The model consists of an input layer with 10 neurons and a ReLU activation function. It then has an output layer with 3 neurons (one for each class) with a softmax activation function. The softmax function is used to convert the raw output scores from the model into probabilities for each class. \n",
    "\n",
    "The `categorical_crossentropy` loss function is appropriate for a multiclass classification problem, especially when the target values are one-hot encoded, as is the case here.\n",
    "\n",
    "By training the model using the Adam optimization algorithm and adjusting the weights based on the categorical crossentropy loss, the neural network learns to make predictions that closely match the actual class labels.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
