{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons and Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons\n",
    "\n",
    "A **neuron**, or artificial neuron, is a foundational building block in neural networks. It's inspired by biological neurons found in our brains. The basic idea behind a neuron is to receive one or more inputs, process them, and produce an output.\n",
    "\n",
    "Mathematically, a neuron performs a weighted sum of its inputs and then passes the result through an activation function. The formula for the output \\( o \\) of a neuron can be represented as:\n",
    "\n",
    "$$\n",
    "o = f\\left( \\sum_{i} w_i \\cdot x_i + b \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\( w_i \\) are the weights associated with each input \\( x_i \\).\n",
    "- \\( b \\) is a bias term.\n",
    "- \\( f \\) is the activation function.\n",
    "\n",
    "Common activation functions include the sigmoid function, hyperbolic tangent (tanh), and Rectified Linear Unit (ReLU).\n",
    "\n",
    "### Layers\n",
    "\n",
    "Neural networks are typically structured into **layers**:\n",
    "\n",
    "1. **Input Layer**: This is where the network takes in data for processing. The number of neurons in this layer matches the number of input features.\n",
    "\n",
    "2. **Hidden Layers**: These are layers between the input and output layers. Deep neural networks have multiple hidden layers, which is where the term \"deep learning\" comes from.\n",
    "\n",
    "3. **Output Layer**: This layer produces the final predictions or classifications of the network. The number of neurons in the output layer depends on the task - for example, it could be 1 for regression tasks or \\( N \\) for a classification task with \\( N \\) classes.\n",
    "\n",
    "Neurons in one layer are typically fully connected to neurons in the next layer. The strength and patterns of these connections, represented by weights, are what get adjusted during training to minimize the difference between the predicted and actual outputs.\n",
    "\n",
    "In summary, neurons are the fundamental units of computation in a neural network, and layers help organize these neurons in a structured manner. Through the process of training, a neural network learns the optimal weights and biases to make accurate predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code provides a simple demonstration of a neuron. When run, it initializes a neuron with three inputs and then computes the output for a given random input vector using the sigmoid activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, input_size, activation_function):\n",
    "        # Initialize random weights and a bias for the neuron\n",
    "        self.weights = np.random.randn(input_size)\n",
    "        self.bias = np.random.randn()\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Compute the output of the neuron based on input data.\"\"\"\n",
    "        # Calculate the weighted sum of inputs\n",
    "        z = np.dot(inputs, self.weights) + self.bias\n",
    "        \n",
    "        # Pass the weighted sum through the activation function\n",
    "        return self.activation_function(z)\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Let's demonstrate the neuron in action:\n",
    "\n",
    "# Create a neuron that takes 3 inputs and uses the sigmoid activation function\n",
    "neuron = Neuron(input_size=3, activation_function=sigmoid)\n",
    "\n",
    "# Provide a random input\n",
    "inputs = np.random.randn(3)\n",
    "\n",
    "# Get the output from the neuron\n",
    "output = neuron.forward(inputs)\n",
    "\n",
    "print(f\"Inputs: {inputs}\")\n",
    "print(f\"Neuron Output: {output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
