{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4501865-abad-4eff-a67d-876dfc88fe98",
   "metadata": {},
   "source": [
    "## 1. Theory Introduction to Model Evaluation and Selection\n",
    "\n",
    "Model evaluation and selection are critical steps in the machine learning workflow. Once we've trained several models, how do we decide which one is best for a given task?\n",
    "\n",
    "### Basics:\n",
    "\n",
    "1. **Model Evaluation**: It refers to the process of examining a model's performance on a dataset, typically a validation or test dataset.\n",
    "\n",
    "2. **Model Selection**: Given multiple models, this process involves selecting the best performing model based on certain criteria like accuracy, F1 score, ROC-AUC, etc.\n",
    "\n",
    "### Important Concepts:\n",
    "\n",
    "- **Training, Validation, and Test Sets**: A dataset is usually split into these three subsets. The training set is used to train the model, the validation set is used to tune hyperparameters, and the test set is used to evaluate the model's final performance.\n",
    "\n",
    "- **Cross-Validation**: It's a method where the training set is split into multiple small sets. A model is trained using k-1 of these sets and validated using the remaining one. This process is repeated k times.\n",
    "\n",
    "- **Metrics**: These are quantitative measures used to evaluate a model's performance. Common metrics include accuracy, precision, recall, F1 score, etc. The choice of metric depends on the specific problem and objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364fedb-1d30-4f86-a194-b67076b295d0",
   "metadata": {},
   "source": [
    "## Library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e489f-5eaf-4e11-bd83-5c3ac8098528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237c210-82f3-40d8-bfa6-50f323c4fe2e",
   "metadata": {},
   "source": [
    "## 2. Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815ecce-1786-4a35-accd-39de0670da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Splitting the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a121bc-a37b-44ae-9255-bc2f7cba1353",
   "metadata": {},
   "source": [
    "## 3. Model coded in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0affb0b-8730-4545-875a-23c3adbe7be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining two models for the comparison purpose\n",
    "svm_model = SVC(kernel='linear')\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Training the models\n",
    "svm_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting on the test set\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluating the models\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "# Using cross-validation for a more robust evaluation\n",
    "svm_cv_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
    "rf_cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"SVM CV Average Score:\", svm_cv_scores.mean())\n",
    "print(\"Random Forest CV Average Score:\", rf_cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e710e355-9c77-4655-a907-fa739009e263",
   "metadata": {},
   "source": [
    "## 4. Explanation\n",
    "\n",
    "In the code provided:\n",
    "\n",
    "1. **Dataset**: We used the Iris dataset, which is a popular dataset for classification tasks. It's split into training and test sets.\n",
    "\n",
    "2. **Models**: Two different models - Support Vector Machine (SVM) with a linear kernel and Random Forest (an ensemble method) - are defined and trained.\n",
    "\n",
    "3. **Evaluation**:\n",
    "    * After training, both models are evaluated on the test set using the accuracy metric.\n",
    "    * For a more robust evaluation, cross-validation is performed on the training data. This ensures that the evaluation is not dependent on a particular train-test split.\n",
    "\n",
    "4. **Results**: The accuracies of both models on the test set and their average cross-validation scores are printed.\n",
    "\n",
    "From the results, the model with a higher average cross-validation score might be considered better. However, it's essential to consider other factors like interpretability, training time, etc., when selecting a model for deployment.\n",
    "\n",
    "Remember, a more complex model (e.g., Random Forest) might perform better on the training data but can overfit, leading to poor generalization to new, unseen data. Always prioritize models that generalize well over those that perform slightly better on training or validation data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
